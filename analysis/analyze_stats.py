#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Analyse statistique et visuelle de la toxicit√© :
 - Lecture des pr√©dictions dans MongoDB
 - Calcul des % l√©g√®rement et tr√®s toxiques par site
 - Graphiques pro : barres comparatives + camembert global
 - Sauvegarde des r√©sultats et d'un r√©sum√© analytique
"""

import datetime
from pymongo import MongoClient
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# =========================
# Connexion MongoDB
# =========================
MONGO_URI = "mongodb://localhost:27017/"
DB_NAME = "articles_db"
PREDICTIONS_COLLECTION = "predictions"
STATS_COLLECTION = "toxicity_stats"

client = MongoClient(MONGO_URI)
db = client[DB_NAME]
predictions_col = db[PREDICTIONS_COLLECTION]
stats_col = db[STATS_COLLECTION]

# =========================
# Lecture des donn√©es
# =========================
predictions = list(predictions_col.find({}, {"_id": 0}))

if not predictions:
    print("‚ö†Ô∏è Aucune donn√©e trouv√©e dans la collection 'predictions'.")
    exit()

df = pd.DataFrame(predictions)
print(f"‚úÖ {len(df)} pr√©dictions charg√©es depuis MongoDB.")

# =========================
# Classification
# =========================
def classify_toxicity(row):
    if row["label"] != "toxique":
        return "non toxique"
    score = float(row.get("score", 0))
    if score >= 0.80:
        return "tr√®s toxique"
    elif score >= 0.50:
        return "l√©g√®rement toxique"
    else:
        return "faible"

df["niveau_toxicite"] = df.apply(classify_toxicity, axis=1)

# =========================
# Agr√©gation par source
# =========================
stats = (
    df.groupby("source")
      .apply(lambda x: pd.Series({
          "total": len(x),
          "pct_leg√®rement_toxique": round((x["niveau_toxicite"] == "l√©g√®rement toxique").mean() * 100, 2),
          "pct_tr√®s_toxique": round((x["niveau_toxicite"] == "tr√®s toxique").mean() * 100, 2),
          "pct_non_toxique": round((x["niveau_toxicite"] == "non toxique").mean() * 100, 2)
      }))
      .reset_index()
)

print("\n=== R√©sum√© par site ===")
print(stats)

# =========================
# STYLE PRO (Seaborn)
# =========================
sns.set_theme(style="whitegrid", font_scale=1.2)
palette = {
    "non toxique": "#4CAF50",          # vert
    "l√©g√®rement toxique": "#FFB300",   # orange
    "leg√®rement toxique": "#FFB300",   # (fallback sans accent)
    "tr√®s toxique": "#E53935"          # rouge
}

# =========================
# BARRES COMPARATIVES
# =========================
bar_data = pd.melt(
    stats,
    id_vars=["source"],
    value_vars=["pct_non_toxique", "pct_leg√®rement_toxique", "pct_tr√®s_toxique"],
    var_name="niveau",
    value_name="pourcentage"
)

# Normalisation des labels (accents)
bar_data["niveau"] = (
    bar_data["niveau"]
    .str.replace("leg√®rement", "l√©g√®rement", regex=False)
    .str.replace("pct_", "")
    .str.replace("_", " ")
)

plt.figure(figsize=(12, 6))
sns.barplot(
    data=bar_data,
    x="source",
    y="pourcentage",
    hue="niveau",
    palette=palette
)
plt.title("Taux de toxicit√© par site", fontsize=16, fontweight="bold")
plt.xlabel("Source")
plt.ylabel("Pourcentage (%)")
plt.xticks(rotation=30, ha="right")
plt.legend(title="Niveau de toxicit√©")
plt.tight_layout()
plt.savefig("comparaison_toxicite_sites.png", dpi=300)
plt.show()
print("üìä Graphique comparatif enregistr√© sous 'comparaison_toxicite_sites.png'")

# =========================
# CAMEMBERT GLOBAL
# =========================
global_counts = df["niveau_toxicite"].value_counts()
colors = [palette.get(k, "#9E9E9E") for k in global_counts.index]

plt.figure(figsize=(6, 6))
plt.pie(
    global_counts,
    labels=global_counts.index,
    autopct="%1.1f%%",
    startangle=140,
    colors=colors,
    explode=[0.02] * len(global_counts)
)
plt.title("R√©partition globale de la toxicit√© des articles", fontsize=14, fontweight="bold")
plt.tight_layout()
plt.savefig("repartition_globale_toxicite.png", dpi=300)
plt.show()
print("ü•ß Camembert global enregistr√© sous 'repartition_globale_toxicite.png'")




# =========================
# CAMEMBERT STYLE AXONE DATA
# =========================
global_counts = df["niveau_toxicite"].value_counts()

# Palette Axone Data stylis√©e
palette_axone = {
    "non toxique": "#003366",         # bleu fonc√© (Axone)
    "l√©g√®rement toxique": "#00B0F0",  # bleu clair
    "tr√®s toxique": "#D9D9D9"         # gris neutre
}

colors = [palette_axone.get(k, "#CCCCCC") for k in global_counts.index]

plt.figure(figsize=(7, 7))
wedges, texts, autotexts = plt.pie(
    global_counts,
    labels=global_counts.index,
    autopct="%1.1f%%",
    startangle=140,
    colors=colors,
    pctdistance=0.85,
    wedgeprops={"linewidth": 1, "edgecolor": "white"}
)

# Cercle blanc central pour effet "donut"
centre_circle = plt.Circle((0, 0), 0.70, fc="white")
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

# Titres et style
plt.title("R√©partition globale de la toxicit√© (Style Axone Data)", fontsize=14, fontweight="bold", color="#003366")
plt.tight_layout()
plt.savefig("repartition_globale_toxicite_axone.png", dpi=300, facecolor="white")
plt.show()

print("üîµ Camembert 'Axone Data' enregistr√© sous 'repartition_globale_toxicite_axone.png'")


# =========================
# STOCKAGE + INTERPR√âTATION
# =========================
snapshot = {
    "created_at": datetime.datetime.utcnow(),
    "results": stats.to_dict(orient="records")
}
stats_col.insert_one(snapshot)
print(f"‚úÖ R√©sultats enregistr√©s dans MongoDB ({STATS_COLLECTION})")

# =========================
# INTERPR√âTATION AUTOMATIQUE
# =========================
top_site = stats.sort_values("pct_tr√®s_toxique", ascending=False).iloc[0]
text = f"""
RAPPORT D‚ÄôANALYSE ‚Äì {datetime.date.today().strftime("%d/%m/%Y")}

1Ô∏è‚É£ Site le plus toxique : {top_site['source']}
   ‚Üí Taux de textes tr√®s toxiques : {top_site['pct_tr√®s_toxique']} %
   ‚Üí Taux de textes l√©g√®rement toxiques : {top_site['pct_leg√®rement_toxique']} %

üí° INTERPR√âTATION :
Les sites pr√©sentant les taux les plus √©lev√©s de toxicit√© sont susceptibles d‚Äôutiliser un ton plus pol√©mique,
des mots √©motionnels ou polarisants. √Ä l‚Äôinverse, les m√©dias comme GameSpot ou France 3 montrent des contenus
majoritairement neutres ou informatifs.

üìà UTILIT√â :
Ces indicateurs peuvent servir de base pour un tableau de bord de suivi de la qualit√© r√©dactionnelle,
ou pour identifier les sources n√©cessitant une mod√©ration plus fine dans un pipeline de monitoring automatique.
"""

with open("rapport_analyse.txt", "w", encoding="utf-8") as f:
    f.write(text.strip())

print("\nüß† Rapport automatique g√©n√©r√© sous 'rapport_analyse.txt'")
