ğŸ§  NLP Toxicity Pipeline
Pipeline Scraping â†’ NLP Classification â†’ FastAPI â†’ MongoDB â†’ Docker

Ce projet implÃ©mente un pipeline complet dâ€™ingÃ©nierie de donnÃ©es textuelles, depuis la collecte dâ€™articles sur plusieurs sites dâ€™actualitÃ© jusquâ€™Ã  la dÃ©tection automatique de toxicitÃ© et son exposition via une API FastAPI conteneurisÃ©e avec Docker.

Il sâ€™agit dâ€™un vrai projet Data Engineer regroupant :
âœ” Web Scraping
âœ” Stockage NoSQL (MongoDB)
âœ” NLP (ModÃ¨le de toxicitÃ©)
âœ” API REST
âœ” Analyse statistique
âœ” Dockerisation complÃ¨te

ğŸ“Œ 1. Architecture du projet



nlp-toxicity-pipeline/
â”‚
â”œâ”€â”€ scraping/           â†’ RÃ©cupÃ©ration des articles (BeautifulSoup)
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ api/                â†’ API FastAPI de classification toxicitÃ©
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”œâ”€â”€ schema.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ analysis/           â†’ Analyse statistique + Graphiques
â”‚   â”œâ”€â”€ analyze_stats.py
â”‚   â”œâ”€â”€ comparaison_toxicite_sites.png
â”‚   â”œâ”€â”€ repartition_globale_toxicite.png
â”‚   â””â”€â”€ toxicite_sites.png
â”‚
â”œâ”€â”€ docs/               â†’ Livrables finaux
â”‚   â”œâ”€â”€ README_original.txt
â”‚   â”œâ”€â”€ Rendu_Test_Technique.docx
â”‚   â””â”€â”€ Rendu_Test_Technique.pptx
â”‚
â”œâ”€â”€ data/               â†’ Datasets (optionnel)
â”‚
â””â”€â”€ README.md           â†’ Documentation principale

ğŸ•¸ï¸ 2. Scraping (Extract)

Le scraping rÃ©cupÃ¨re automatiquement des articles rÃ©cents depuis plusieurs sites :

humanite.fr

gamespot.com

marianne.net

lemonde.fr

france24.com

franceinfo.fr

mediacites.fr

lepoint.fr

Chaque article contient :
âœ” URL
âœ” Titre
âœ” Contenu textuel

Les donnÃ©es sont stockÃ©es dans MongoDB via docker-compose.

Lancer le scraping :
cd scraping
pip install -r requirements.txt
python scraper.py

ğŸ¤– 3. NLP Toxicity Classification (Transform)

Lâ€™API utilise un modÃ¨le NLP (HuggingFace ou modÃ¨le custom) pour prÃ©dire si un texte est :

ğŸ”´ TrÃ¨s toxique

ğŸŸ  LÃ©gÃ¨rement toxique

ğŸŸ¢ Non toxique

Chaque prÃ©diction est stockÃ©e dans MongoDB avec :
âœ” texte
âœ” prÃ©diction
âœ” score
âœ” timestamp

ğŸŒ 4. API FastAPI (Load)

Lâ€™API expose un endpoint principal :

POST /predict

Input :

{
  "text": "Contenu textuel ici..."
}


Output :

{
  "prediction": "toxic",
  "confidence": 0.92
}

Lancer l'API :
cd api
uvicorn app.api:app --reload

ğŸ“Š 5. Analyse statistique

Le script analyze_stats.py :

Calcule le pourcentage de toxicitÃ© par site

GÃ©nÃ¨re des graphiques (PNG)

Stocke les rÃ©sultats dans MongoDB

Produit une interprÃ©tation finale

GÃ©nÃ©rer les statistiques :
cd analysis
python analyze_stats.py


Graphiques :

comparaison_toxicite_sites.png

repartition_globale_toxicite.png

toxicite_sites.png

ğŸ³ 6. DÃ©ploiement Docker
Lancer toute lâ€™infrastructure :
docker compose up --build


Lâ€™API sera disponible sur :
ğŸ‘‰ http://localhost:8000

ğŸ§° 7. Technologies utilisÃ©es

Python 3.x

BeautifulSoup

FastAPI

MongoDB

Uvicorn

Transformers / NLP

Pandas, Matplotlib, Seaborn

Docker & Docker Compose

ğŸ“ 8. CompÃ©tences dÃ©montrÃ©es

âœ” Web Scraping robuste
âœ” Pipeline ETL complet
âœ” CrÃ©ation API REST
âœ” Traitement NLP
âœ” Visualisation Data
âœ” Base de donnÃ©es NoSQL
âœ” Conteneurisation Docker
âœ” Architecture projet propre et modulaire

ğŸ‘¤ Auteur

Wail Brimesse
Bachelor Data & IA â€“ ECE Paris
Recherche : Stage 6 mois (Data Engineer / Data Analyst / Data Scientist) â€“ Mars 2026

ğŸš€ 9. AmÃ©liorations possibles

SystÃ¨me de retries + proxy pour scraping

Dashboard Streamlit

CI/CD GitHub Actions

DÃ©ploiement cloud (AWS / Render / Railway)

ModÃ¨le NLP entraÃ®nÃ© sur mesure
